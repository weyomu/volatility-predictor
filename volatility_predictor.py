# -*- coding: utf-8 -*-
"""
æ¯”ç‰¹å¸æ³¢åŠ¨é¢„è­¦ç³»ç»Ÿ
ä¸“æ³¨äºé¢„æµ‹æœªæ¥1-3å¤©æ˜¯å¦ä¼šå‡ºç°å¤§æ¶¨å¤§è·Œ
ä¸æ¶‰åŠäº¤æ˜“ï¼Œåªåšé£é™©é¢„è­¦
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (14, 8)

# =============================================================================
# 1. è¾…åŠ©å‡½æ•°ï¼ˆä¸åŸå§‹ä»£ç ç›¸åŒï¼‰
# =============================================================================

def convert_volume(vol_str):
    """è½¬æ¢äº¤æ˜“é‡æ ¼å¼"""
    if isinstance(vol_str, str):
        vol_str = vol_str.replace(',', '')
        if 'B' in vol_str:
            return float(vol_str.replace('B', '')) * 1e9
        elif 'M' in vol_str:
            return float(vol_str.replace('M', '')) * 1e6
        elif 'K' in vol_str:
            return float(vol_str.replace('K', '')) * 1e3
        else:
            return float(vol_str)
    return vol_str

def convert_change(change_str):
    """è½¬æ¢æ¶¨è·Œå¹…æ ¼å¼"""
    if isinstance(change_str, str):
        clean_str = change_str.replace('%', '').replace(',', '').strip()
        if clean_str == '-' or clean_str == 'nan':
            return 0.0
        return float(clean_str) / 100
    return change_str

def calculate_rsi(series, period=14):
    """è®¡ç®—RSIæŒ‡æ ‡"""
    series = pd.to_numeric(series, errors='coerce')
    delta = series.diff(1)
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    avg_gain = gain.ewm(alpha=1/period, min_periods=period).mean()
    avg_loss = loss.ewm(alpha=1/period, min_periods=period).mean()
    
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    return rsi.replace([np.inf, -np.inf], np.nan).fillna(50)

def calculate_atr(data, period=14):
    """è®¡ç®—ATRæŒ‡æ ‡"""
    high = data['é«˜']
    low = data['ä½']
    close = data['æ”¶ç›˜']
    
    tr1 = high - low
    tr2 = abs(high - close.shift(1))
    tr3 = abs(low - close.shift(1))
    
    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    atr = tr.ewm(alpha=1/period, min_periods=period).mean()
    return atr

# =============================================================================
# 2. æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹ï¼ˆä¸åŸå§‹ä»£ç ç›¸åŒï¼‰
# =============================================================================

def load_and_engineer_features(filepath):
    """åŠ è½½æ•°æ®å¹¶è¿›è¡Œç‰¹å¾å·¥ç¨‹"""
    # åŠ è½½æ•°æ®
    df = pd.read_csv(filepath, parse_dates=['æ—¥æœŸ'])
    df = df[df['æ—¥æœŸ'].dt.year > 2000]
    
    # è½¬æ¢æ ¼å¼
    df['äº¤æ˜“é‡'] = df['äº¤æ˜“é‡'].apply(convert_volume)
    df['æ¶¨è·Œå¹…'] = df['æ¶¨è·Œå¹…'].apply(convert_change)
    
    # ç¡®ä¿ä»·æ ¼åˆ—æ˜¯æ•°å€¼ç±»å‹
    for col in ['æ”¶ç›˜', 'å¼€ç›˜', 'é«˜', 'ä½']:
        df[col] = df[col].astype(str).str.replace(',', '').str.replace('$', '').str.replace('Â¥', '')
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æ’åºå’Œè®¾ç½®ç´¢å¼•
    df.sort_values('æ—¥æœŸ', inplace=True)
    df.set_index('æ—¥æœŸ', inplace=True)
    df.fillna(method='ffill', inplace=True)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.fillna(method='ffill', inplace=True)
    
    # ç‰¹å¾å·¥ç¨‹
    df['æ—¥å˜åŒ–'] = df['æ”¶ç›˜'].diff()
    df['å¼€ç›˜æ”¶ç›˜å·®'] = df['æ”¶ç›˜'] - df['å¼€ç›˜']
    df['é«˜ä½å·®'] = df['é«˜'] - df['ä½']
    df['SMA_7'] = df['æ”¶ç›˜'].rolling(window=7, min_periods=1).mean()
    df['SMA_30'] = df['æ”¶ç›˜'].rolling(window=30, min_periods=1).mean()
    df['EMA_12'] = df['æ”¶ç›˜'].ewm(span=12, adjust=False, min_periods=1).mean()
    df['EMA_26'] = df['æ”¶ç›˜'].ewm(span=26, adjust=False, min_periods=1).mean()
    df['MACD'] = df['EMA_12'] - df['EMA_26']
    df['ä¿¡å·çº¿'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = df['MACD'] - df['ä¿¡å·çº¿']
    df['æ³¢åŠ¨ç‡'] = df['æ”¶ç›˜'].rolling(window=60, min_periods=1).std()
    df['RSI'] = calculate_rsi(df['æ”¶ç›˜'], 14)
    df['ä¸­è½¨'] = df['æ”¶ç›˜'].rolling(window=20).mean()
    df['ä¸Šè½¨'] = df['ä¸­è½¨'] + 2 * df['æ”¶ç›˜'].rolling(window=20).std()
    df['ä¸‹è½¨'] = df['ä¸­è½¨'] - 2 * df['æ”¶ç›˜'].rolling(window=20).std()
    df['ATR'] = calculate_atr(df, 14)
    
    # æ»åç‰¹å¾
    for i in range(1, 61):
        df[f'æ»å_{i}'] = df['æ”¶ç›˜'].shift(i)
    
    df.dropna(inplace=True)
    return df

# =============================================================================
# 3. ğŸ†• å…³é”®æ”¹è¿›ï¼šå®šä¹‰æ³¢åŠ¨æ ‡ç­¾ï¼ˆåŸå§‹ä»£ç æ²¡æœ‰è¿™ä¸ªï¼ï¼‰
# =============================================================================

def create_volatility_labels(df, days_ahead=1, threshold=0.03):
    """
    åˆ›å»ºæ³¢åŠ¨æ ‡ç­¾
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    - å¦‚æœæœªæ¥Nå¤©æ¶¨è·Œå¹…ç»å¯¹å€¼ > thresholdï¼Œæ ‡è®°ä¸º"é«˜æ³¢åŠ¨"
    - å¦åˆ™æ ‡è®°ä¸º"ä½æ³¢åŠ¨"
    
    å‚æ•°:
        days_ahead: é¢„æµ‹æœªæ¥å¤šå°‘å¤©ï¼ˆ1-3å¤©ï¼‰
        threshold: æ³¢åŠ¨é˜ˆå€¼ï¼ˆ3% = 0.03ï¼‰
    
    è¿”å›:
        0 = ä½æ³¢åŠ¨ï¼ˆæ­£å¸¸ï¼‰
        1 = é«˜æ³¢åŠ¨ï¼ˆå¤§æ¶¨å¤§è·Œï¼‰
    """
    future_returns = []
    
    for i in range(days_ahead):
        future_price = df['æ”¶ç›˜'].shift(-(i+1))
        ret = (future_price - df['æ”¶ç›˜']) / df['æ”¶ç›˜']
        future_returns.append(ret.abs())
    
    # å–æœªæ¥Nå¤©çš„æœ€å¤§æ¶¨è·Œå¹…
    max_future_change = pd.concat(future_returns, axis=1).max(axis=1)
    
    # æ ‡è®°é«˜æ³¢åŠ¨
    labels = (max_future_change > threshold).astype(int)
    
    return labels, max_future_change

# =============================================================================
# 4. ğŸ†• å…³é”®æ”¹è¿›ï¼šæ­£ç¡®çš„æ•°æ®åˆ’åˆ†ï¼ˆé¿å…æ•°æ®æ³„æ¼ï¼‰
# =============================================================================

def prepare_data_for_classification(df, labels, time_steps=60, train_ratio=0.8):
    """
    å‡†å¤‡åˆ†ç±»æ•°æ®ï¼ˆé¢„æµ‹é«˜æ³¢åŠ¨/ä½æ³¢åŠ¨ï¼‰
    
    ğŸ”‘ å…³é”®æ”¹è¿›ï¼šå…ˆåˆ’åˆ†å†æ ‡å‡†åŒ–ï¼Œé¿å…æ•°æ®æ³„æ¼ï¼
    """
    feature_cols = [col for col in df.columns if not col.startswith('ç›®æ ‡_')]
    
    # å…ˆæŒ‰æ—¶é—´åˆ’åˆ†
    split_idx = int(len(df) * train_ratio)
    train_df = df.iloc[:split_idx].copy()
    test_df = df.iloc[split_idx:].copy()
    train_labels = labels[:split_idx]
    test_labels = labels[split_idx:]
    
    print(f"è®­ç»ƒé›†æ—¶é—´: {train_df.index[0]} åˆ° {train_df.index[-1]}")
    print(f"æµ‹è¯•é›†æ—¶é—´: {test_df.index[0]} åˆ° {test_df.index[-1]}")
    
    # âœ… åªç”¨è®­ç»ƒé›†æ‹Ÿåˆscaler
    scaler = MinMaxScaler()
    scaler.fit(train_df[feature_cols])
    
    train_scaled = scaler.transform(train_df[feature_cols])
    test_scaled = scaler.transform(test_df[feature_cols])
    
    # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®é›†
    def create_sequences(data, labels, time_steps):
        X, y = [], []
        for i in range(len(data) - time_steps):
            X.append(data[i:(i + time_steps), :])
            y.append(labels[i + time_steps])
        return np.array(X), np.array(y)
    
    X_train, y_train = create_sequences(train_scaled, train_labels, time_steps)
    X_test, y_test = create_sequences(test_scaled, test_labels, time_steps)
    
    return {
        'X_train': X_train,
        'y_train': y_train,
        'X_test': X_test,
        'y_test': y_test,
        'test_dates': test_df.index[time_steps:],
        'test_prices': test_df['æ”¶ç›˜'].values[time_steps:],
        'scaler': scaler,
        'feature_cols': feature_cols
    }

# =============================================================================
# 5. æ„å»ºåˆ†ç±»æ¨¡å‹ï¼ˆé¢„æµ‹é«˜æ³¢åŠ¨/ä½æ³¢åŠ¨ï¼‰
# =============================================================================

def create_volatility_classifier(input_shape):
    """åˆ›å»ºæ³¢åŠ¨åˆ†ç±»æ¨¡å‹"""
    model = Sequential([
        LSTM(64, return_sequences=True, input_shape=input_shape),
        Dropout(0.3),
        LSTM(32, return_sequences=False),
        Dropout(0.3),
        Dense(16, activation='relu'),
        Dense(1, activation='sigmoid')  # äºŒåˆ†ç±»ï¼š0=ä½æ³¢åŠ¨ï¼Œ1=é«˜æ³¢åŠ¨
    ])
    
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

# =============================================================================
# 6. ä¸»å‡½æ•°
# =============================================================================

def main():
    print("="*70)
    print("æ¯”ç‰¹å¸æ³¢åŠ¨é¢„è­¦ç³»ç»Ÿ")
    print("é¢„æµ‹æœªæ¥1-3å¤©æ˜¯å¦ä¼šå‡ºç°å¤§æ¶¨å¤§è·Œ")
    print("="*70)
    
    # å¯è°ƒå‚æ•°
    DAYS_AHEAD = 1        # é¢„æµ‹æœªæ¥å‡ å¤©ï¼ˆ1-3å¤©ï¼‰
    THRESHOLD = 0.03      # æ³¢åŠ¨é˜ˆå€¼ï¼š3%
    TIME_STEPS = 60       # ä½¿ç”¨è¿‡å»60å¤©æ•°æ®
    TRAIN_RATIO = 0.8     # 80%è®­ç»ƒï¼Œ20%æµ‹è¯•
    
    print(f"\nå‚æ•°è®¾ç½®:")
    print(f"- é¢„æµ‹æ—¶é•¿: æœªæ¥{DAYS_AHEAD}å¤©")
    print(f"- æ³¢åŠ¨é˜ˆå€¼: {THRESHOLD*100}% (è¶…è¿‡æ­¤å€¼è§†ä¸ºé«˜æ³¢åŠ¨)")
    print(f"- è®­ç»ƒé›†æ¯”ä¾‹: {TRAIN_RATIO*100}%")
    
    # 1. åŠ è½½æ•°æ®
    print("\n[1/5] åŠ è½½æ•°æ®å’Œç‰¹å¾å·¥ç¨‹...")
    df = load_and_engineer_features('æ¯”ç‰¹å¸å†å²æ•°æ®2.csv')
    print(f"æ•°æ®æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
    print(f"æ€»æ•°æ®é‡: {len(df)} å¤©")
    
    # 2. åˆ›å»ºæ³¢åŠ¨æ ‡ç­¾
    print(f"\n[2/5] åˆ›å»ºæ³¢åŠ¨æ ‡ç­¾ï¼ˆé˜ˆå€¼ï¼š{THRESHOLD*100}%ï¼‰...")
    labels, future_changes = create_volatility_labels(df, days_ahead=DAYS_AHEAD, threshold=THRESHOLD)
    
    # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    high_vol_count = labels.sum()
    low_vol_count = len(labels) - high_vol_count
    print(f"é«˜æ³¢åŠ¨å¤©æ•°: {high_vol_count} ({high_vol_count/len(labels)*100:.1f}%)")
    print(f"ä½æ³¢åŠ¨å¤©æ•°: {low_vol_count} ({low_vol_count/len(labels)*100:.1f}%)")
    
    # 3. å‡†å¤‡æ•°æ®
    print("\n[3/5] å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼ˆé¿å…æ•°æ®æ³„æ¼ï¼‰...")
    data = prepare_data_for_classification(df, labels, time_steps=TIME_STEPS, train_ratio=TRAIN_RATIO)
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(data['X_train'])} (é«˜æ³¢åŠ¨: {data['y_train'].sum()})")
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(data['X_test'])} (é«˜æ³¢åŠ¨: {data['y_test'].sum()})")
    
    # 4. è®­ç»ƒæ¨¡å‹
    print("\n[4/5] è®­ç»ƒæ³¢åŠ¨é¢„æµ‹æ¨¡å‹...")
    model = create_volatility_classifier(
        input_shape=(data['X_train'].shape[1], data['X_train'].shape[2])
    )
    
    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    
    history = model.fit(
        data['X_train'], data['y_train'],
        validation_split=0.2,
        epochs=50,
        batch_size=32,
        callbacks=[early_stop],
        verbose=0
    )
    print("æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    
    # 5. æµ‹è¯•é›†è¯„ä¼°
    print("\n[5/5] åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°...")
    y_pred_prob = model.predict(data['X_test'], verbose=0).flatten()
    y_pred = (y_pred_prob > 0.5).astype(int)  # æ¦‚ç‡>0.5è§†ä¸ºé«˜æ³¢åŠ¨
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    
    accuracy = accuracy_score(data['y_test'], y_pred)
    precision = precision_score(data['y_test'], y_pred, zero_division=0)
    recall = recall_score(data['y_test'], y_pred, zero_division=0)
    f1 = f1_score(data['y_test'], y_pred, zero_division=0)
    
    print("\n" + "="*70)
    print("æ¨¡å‹æ€§èƒ½è¯„ä¼°")
    print("="*70)
    print(f"å‡†ç¡®ç‡ (Accuracy):  {accuracy*100:.2f}%  - é¢„æµ‹å¯¹çš„æ¯”ä¾‹")
    print(f"ç²¾ç¡®ç‡ (Precision): {precision*100:.2f}%  - é¢„è­¦å‡†ç¡®åº¦ï¼ˆé¢„è­¦æ—¶çœŸçš„é«˜æ³¢åŠ¨çš„æ¦‚ç‡ï¼‰")
    print(f"å¬å›ç‡ (Recall):    {recall*100:.2f}%  - æ•è·ç‡ï¼ˆé«˜æ³¢åŠ¨æ—¶èƒ½é¢„è­¦çš„æ¦‚ç‡ï¼‰")
    print(f"F1åˆ†æ•°:            {f1:.3f}     - ç»¼åˆæŒ‡æ ‡ï¼ˆç²¾ç¡®ç‡å’Œå¬å›ç‡çš„å¹³å‡ï¼‰")
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(data['y_test'], y_pred)
    print(f"\næ··æ·†çŸ©é˜µ:")
    print(f"              é¢„æµ‹ä½æ³¢åŠ¨  é¢„æµ‹é«˜æ³¢åŠ¨")
    print(f"å®é™…ä½æ³¢åŠ¨:      {cm[0,0]:4d}       {cm[0,1]:4d}")
    print(f"å®é™…é«˜æ³¢åŠ¨:      {cm[1,0]:4d}       {cm[1,1]:4d}")
    
    # 6. æ‰¾å‡ºæœ€è¿‘çš„é«˜æ³¢åŠ¨é¢„è­¦
    print("\n" + "="*70)
    print("æœ€è¿‘çš„é«˜æ³¢åŠ¨é¢„è­¦äº‹ä»¶")
    print("="*70)
    
    high_vol_indices = np.where(y_pred == 1)[0]
    if len(high_vol_indices) > 0:
        # æ˜¾ç¤ºæœ€è¿‘10ä¸ªé¢„è­¦
        recent_warnings = high_vol_indices[-10:] if len(high_vol_indices) >= 10 else high_vol_indices
        
        for idx in recent_warnings:
            date = data['test_dates'][idx]
            price = data['test_prices'][idx]
            prob = y_pred_prob[idx]
            actual = data['y_test'][idx]
            
            status = "âœ… æ­£ç¡®é¢„è­¦" if actual == 1 else "âŒ è¯¯æŠ¥"
            print(f"{date.strftime('%Y-%m-%d')} | ä»·æ ¼: ${price:,.2f} | é¢„è­¦æ¦‚ç‡: {prob*100:.1f}% | {status}")
    else:
        print("æµ‹è¯•é›†ä¸­æ²¡æœ‰é¢„è­¦é«˜æ³¢åŠ¨äº‹ä»¶")
    
    # 7. é¢„æµ‹æœªæ¥
    print("\n" + "="*70)
    print(f"æœªæ¥{DAYS_AHEAD}å¤©æ³¢åŠ¨é¢„è­¦")
    print("="*70)
    
    # ä½¿ç”¨æœ€æ–°æ•°æ®é¢„æµ‹
    latest_data = data['X_test'][-1:]
    future_prob = model.predict(latest_data, verbose=0)[0][0]
    future_pred = 1 if future_prob > 0.5 else 0
    
    latest_date = data['test_dates'][-1]
    latest_price = data['test_prices'][-1]
    
    print(f"å½“å‰æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}")
    print(f"å½“å‰ä»·æ ¼: ${latest_price:,.2f}")
    print(f"\næœªæ¥{DAYS_AHEAD}å¤©æ³¢åŠ¨é¢„æµ‹:")
    print(f"é«˜æ³¢åŠ¨æ¦‚ç‡: {future_prob*100:.1f}%")
    
    if future_pred == 1:
        print(f"âš ï¸  é¢„è­¦ï¼šæœªæ¥{DAYS_AHEAD}å¤©å¯èƒ½å‡ºç°å¤§æ¶¨å¤§è·Œï¼ˆæ¶¨è·Œå¹…>Â±{THRESHOLD*100}%ï¼‰")
        print(f"å»ºè®®ï¼šæ³¨æ„é£é™©ï¼Œè€ƒè™‘æ­¢æŸæˆ–è§‚æœ›")
    else:
        print(f"âœ… æ­£å¸¸ï¼šæœªæ¥{DAYS_AHEAD}å¤©é¢„è®¡æ³¢åŠ¨è¾ƒå°")
        print(f"å»ºè®®ï¼šå¸‚åœºç›¸å¯¹ç¨³å®šï¼Œå¯æ­£å¸¸æ“ä½œ")
    
    # 8. å¯è§†åŒ–
    print("\nç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # å›¾1: æµ‹è¯•é›†é¢„æµ‹ç»“æœ
    plt.figure(figsize=(16, 10))
    
    # å­å›¾1: ä»·æ ¼å’Œæ³¢åŠ¨é¢„è­¦
    plt.subplot(3, 1, 1)
    plt.plot(data['test_dates'], data['test_prices'], label='ä»·æ ¼', linewidth=2, color='blue')
    
    # æ ‡è®°å®é™…é«˜æ³¢åŠ¨ç‚¹
    actual_high_vol = np.where(data['y_test'] == 1)[0]
    if len(actual_high_vol) > 0:
        plt.scatter(data['test_dates'][actual_high_vol], 
                   data['test_prices'][actual_high_vol],
                   color='red', s=100, marker='x', label='å®é™…é«˜æ³¢åŠ¨', zorder=5)
    
    # æ ‡è®°é¢„æµ‹é«˜æ³¢åŠ¨ç‚¹
    pred_high_vol = np.where(y_pred == 1)[0]
    if len(pred_high_vol) > 0:
        plt.scatter(data['test_dates'][pred_high_vol], 
                   data['test_prices'][pred_high_vol],
                   color='orange', s=100, marker='o', alpha=0.5, label='é¢„æµ‹é«˜æ³¢åŠ¨', zorder=4)
    
    plt.title(f'æ¯”ç‰¹å¸ä»·æ ¼ä¸æ³¢åŠ¨é¢„è­¦ (é˜ˆå€¼ï¼š{THRESHOLD*100}%)', fontsize=16)
    plt.ylabel('ä»·æ ¼ (ç¾å…ƒ)', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2: é¢„æµ‹æ¦‚ç‡æ›²çº¿
    plt.subplot(3, 1, 2)
    plt.plot(data['test_dates'], y_pred_prob, label='é«˜æ³¢åŠ¨æ¦‚ç‡', linewidth=2, color='purple')
    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='é¢„è­¦é˜ˆå€¼(50%)')
    plt.fill_between(data['test_dates'], 0, y_pred_prob, 
                     where=(y_pred_prob > 0.5), alpha=0.3, color='red', label='é«˜æ³¢åŠ¨åŒº')
    plt.title('é«˜æ³¢åŠ¨é¢„æµ‹æ¦‚ç‡', fontsize=16)
    plt.ylabel('æ¦‚ç‡', fontsize=12)
    plt.ylim(0, 1)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾3: æ··æ·†çŸ©é˜µ
    plt.subplot(3, 1, 3)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['é¢„æµ‹ä½æ³¢åŠ¨', 'é¢„æµ‹é«˜æ³¢åŠ¨'],
                yticklabels=['å®é™…ä½æ³¢åŠ¨', 'å®é™…é«˜æ³¢åŠ¨'])
    plt.title('æ··æ·†çŸ©é˜µ', fontsize=16)
    
    plt.tight_layout()
    plt.savefig('æ³¢åŠ¨é¢„è­¦ç»“æœ.png', dpi=150)
    print("âœ“ ä¿å­˜å›¾è¡¨: æ³¢åŠ¨é¢„è­¦ç»“æœ.png")
    
    # ä¿å­˜é¢„è­¦è®°å½•
    if len(high_vol_indices) > 0:
        warnings_df = pd.DataFrame({
            'æ—¥æœŸ': [data['test_dates'][i].strftime('%Y-%m-%d') for i in high_vol_indices],
            'ä»·æ ¼': [data['test_prices'][i] for i in high_vol_indices],
            'é¢„è­¦æ¦‚ç‡': [y_pred_prob[i] for i in high_vol_indices],
            'å®é™…æ³¢åŠ¨': ['é«˜æ³¢åŠ¨' if data['y_test'][i] == 1 else 'ä½æ³¢åŠ¨' for i in high_vol_indices],
            'é¢„è­¦ç»“æœ': ['æ­£ç¡®' if data['y_test'][i] == 1 else 'è¯¯æŠ¥' for i in high_vol_indices]
        })
        warnings_df.to_csv('æ³¢åŠ¨é¢„è­¦è®°å½•.csv', index=False, encoding='utf-8-sig')
        print("âœ“ ä¿å­˜æ–‡ä»¶: æ³¢åŠ¨é¢„è­¦è®°å½•.csv")
    
    print("\n" + "="*70)
    print("æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
    print("="*70)
    
    # è¿”å›ç»“æœä¾›è¿›ä¸€æ­¥åˆ†æ
    return {
        'model': model,
        'data': data,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'future_prob': future_prob
    }

if __name__ == "__main__":
    results = main()

